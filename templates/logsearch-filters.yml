
properties:
  <<: (( merge ))
  logstash_parser:
    filters: "# Parse Cloud Foundry logs from loggregator (syslog)\n# see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156\n\nif [@type] in [\"syslog\", \"relp\"] and [syslog_program] == \"doppler\" {\n# Parse Cloud Foundry logs from doppler (via https://github.com/SpringerPE/firehose-to-syslog)\n\njson {\n    source => 'syslog_message'\n    add_tag => [ 'cloudfoundry_doppler' ] #This is only added if json parsing is successful\n}\n\nif \"_jsonparsefailure\" in [tags] {\n    \n    # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard \n    mutate {\n        add_tag => [\"fail/cloudfoundry/doppler/jsonparsefailure_of_syslog_message\"]\n        remove_tag => [\"_jsonparsefailure\"]\n    }\n\n} else {\n\n    date {\n        match => [ \"time\", \"ISO8601\" ]\n    }\n\n    # Replace the unicode newline character \\u2028 with \\n, which Kibana will display as a new line.  Seems that passing a string with an actual newline in it is the only way to make gsub work\n    mutate {\n      gsub => [ \"msg\", '\\u2028', \"\n\"\n      ]\n    }\n\n    if ('RTR' in [source_type]) {\n        grok { \n            #cf-release > v205 - includes RequestBytesReceived\n            match => { 'msg' => '%{HOSTNAME:hostname} - \\[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\\] \\\"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\\\" %{BASE10NUM:status:int} %{BASE10NUM:request_bytes_received:int} %{BASE10NUM:body_bytes_sent:int} \\\"%{GREEDYDATA:referer}\\\" \\\"%{GREEDYDATA:http_user_agent}\\\" %{HOSTPORT} x_forwarded_for:\\\"%{GREEDYDATA:x_forwarded_for}\\\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }\n            \n            #cf-release <= v205  \n\t    match => { 'msg' => '%{HOSTNAME:hostname} - \\[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\\] \\\"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\\\" %{BASE10NUM:status:int} %{BASE10NUM:body_bytes_sent:int} \\\"%{GREEDYDATA:referer}\\\" \\\"%{GREEDYDATA:http_user_agent}\\\" %{HOSTPORT} x_forwarded_for:\\\"%{GREEDYDATA:x_forwarded_for}\\\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }\n\t    overwrite => [ \"time\" ]\n\t    tag_on_failure => [ 'fail/cloudfoundry/doppler/RTR' ]\n        }\n\n        if !(\"fail/cloudfoundry/doppler/RTR\" in [tags]) {\n            date {\n                match => [ \"time\", \"dd/MM/y:HH:mm:ss Z\" ]\n            }\n            if [x_forwarded_for] {\n                mutate {\n                    gsub => [\"x_forwarded_for\",\"[\\s\\\\\"]\",\"\"] # remove quotes and whitespace\n                    split => [\"x_forwarded_for\", \",\"] # format is client, proxy1, proxy2 ...\n                }\n\n               mutate {\n                  add_field => [\"remote_addr\", \"%{x_forwarded_for[0]}\"]\n               }\n                            \n               geoip {\n                 source => \"remote_addr\"\n               }\n            }\n\n            mutate {\n                remove => [ \"msg\" ]\n            }\n        }\n    }\n\n    #Ensure that we always have an event_type, in prep for adding metrics\n    if ![event_type] {\n        mutate {\n            add_field => [ \"event_type\", \"LogMessage\" ]\n        }\n    }\n\n    mutate {\n        remove_field => \"@type\"\n    }\n\n    mutate {\n        add_field => [ \"@type\", \"cloudfoundry_doppler\" ]\n        rename => [ \"syslog_message\", \"@message\" ]\n        remove_field => \"time\"\n        remove_field => \"syslog_severity_code\"\n        remove_field => \"syslog_facility_code\"\n        remove_field => \"syslog_facility\"\n        remove_field => \"syslog_severity\"\n        remove_field => \"syslog_pri\"\n        remove_field => \"syslog_program\"\n        remove_field => \"syslog_pid\"\n    }\n}\n\n\n    \n\n} else if [@type] in [\"syslog\", \"relp\"] and [@source.host] == \"loggregator\" {\n# Parse Cloud Foundry logs from loggregator (syslog)\n# see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156\n\nmutate {\n    add_field => [ \"tmp_syslog_procid\" ,\"%{syslog_procid}\" ]\n}\n\n# [App/0] => [App, 0]\nmutate {\n    gsub => [ \"tmp_syslog_procid\", \"[\\[\\]]\", \"\" ]\n    split => [ \"tmp_syslog_procid\", \"/\" ]\n    add_field => [ \"source_type\" ,\"%{[tmp_syslog_procid][0]}\"  ]\n    add_field => [ \"source_instance\" ,\"%{[tmp_syslog_procid][1]}\"  ]\n    remove_field => [ \"tmp_syslog_procid\" ]\n}\n\n# For source types with no instance number, remove the field\nif [source_instance] == \"%{[tmp_syslog_procid][1]}\" {\n    mutate {\n      remove_field => [ \"source_instance\" ]\n    }\n}\n\n#If it looks like JSON, it must be JSON...\nif [syslog_message] =~ /^\\s*{\".*}\\s*$/ {\n    json {\n        source => \"syslog_message\"\n    }\n     # @todo seems like some messages have @timestamp in them? seems ci-specific\n    date {\n        match => [ \"@timestamp\", \"ISO8601\" ]\n    }\n} else {\n    mutate {\n        add_field => [ \"message\", \"%{syslog_message}\" ]\n    }\n    if [message] == \"-\" {\n        mutate {\n            remove_field => \"message\"\n        }\n    }\n}\n mutate {\n    rename => [ \"syslog_program\", \"@source.app_id\" ]\n}\n mutate {\n    add_tag => \"cloudfoundry_loggregator\"\n    remove_field => \"syslog_facility\"\n    remove_field => \"syslog_facility_code\"\n    remove_field => \"syslog_message\"\n    remove_field => \"syslog_severity\"\n    remove_field => \"syslog_severity_code\"\n    remove_field => \"syslog5424_ver\"\n    remove_field => \"syslog6587_msglen\"\n}\n\n} else if [@type] in [\"syslog\", \"relp\"] and [syslog_program] =~ /vcap\\..*/ {\n# Parse Cloud Foundry logs from syslog_aggregator\n\ngrok {\n    match => { \"syslog_message\" => \"(?:\\[job=%{NOTSPACE:@job.name}|-) +(?:index=%{NOTSPACE:@job.index}\\]|-) %{GREEDYDATA:_message_json}\" }\n    tag_on_failure => [\n        \"_grokparsefailure-cf-vcap\"\n    ]\n}\n\nif !(\"_grokparsefailure-cf-vcap\" in [tags]) {\n    kv {\n        source => \"msgdata\"\n        field_split => \" \"\n        target => \"msgdata\"\n    }\n\n    json {\n        source => \"_message_json\"\n        remove_field => \"_message_json\"\n    }\n\n    mutate {\n        rename => [ \"syslog_program\", \"@shipper.name\" ]\n        replace => [ \"@job.host\", \"%{@source.host}\" ]\n        gsub => [\n            \"@shipper.name\", \"\\.\", \"_\",\n            \"@job.name\", \"\\.\", \"_\"\n          ]\n    }\n\n    if [source] == \"NatsStreamForwarder\" {\n        json {\n            source => \"[data][nats_message]\"\n            target => \"nats_message\"\n        }\n\n        mutate {\n            remove_field => \"[data][nats_message]\"\n        }\n    }\n\n    mutate {\n        add_tag => \"cloudfoundry_vcap\"\n        replace => [ \"@shipper.priority\", \"%{syslog_pri}\" ]\n        replace => [ \"@shipper.name\", \"%{@shipper.name}_%{@type}\" ]\n        replace => [ \"@type\", \"%{@type}_cf\" ]\n    }\n\n    mutate {\n        remove_field => \"syslog_facility\"\n        remove_field => \"syslog_facility_code\"\n        remove_field => \"syslog_message\"\n        remove_field => \"syslog_severity\"\n        remove_field => \"syslog_severity_code\"\n    }\n}\n\n}\n"
  elasticsearch_config:
    templates:
      - logsearch-for-cloudfoundry: "{\n    \"template\" : \"logstash-*\",\n    \"order\" : 50,\n    \"settings\" : {\n\t\"number_of_shards\" : 5,\n\t\"number_of_replicas\" : 1,\n\t\"index\" : {\n            \"search\" : {\n\t\t\"slowlog\" : {\n                    \"threshold\" : {\n\t\t\t\"query\" : {\n                            \"warn\" : \"15s\",\n                            \"info\" : \"10s\",\n                            \"debug\" : \"5s\",\n                            \"trace\" : \"500ms\"\n\t\t\t}\n                    }\n\t\t}\n            },\n            \"query\" : {\n\t\t\"default_field\" : \"@message\"\n            },\n            \"store\" : {\n\t\t\"compress\" : {\n                    \"stored\" : true,\n                    \"tv\": true\n\t\t}\n            }\n\t}\n    },\n    \"mappings\": {\n\t\"_default_\": {\n            \"_all\": {\n\t\t\"enabled\": false\n            },\n            \"_source\": {\n\t\t\"compress\": true\n            },\n            \"dynamic_templates\": [\n\t\t{\n                    \"string_template\" : {\n\t\t\t\"match\" : \"*\",\n\t\t\t\"mapping\": {\n                            \"type\": \"string\",\n                            \"index\": \"not_analyzed\",\n                            \"norms\" : {\n\t\t\t\t\"enabled\" : false\n                            }\n\t\t\t},\n\t\t\t\"match_mapping_type\" : \"string\"\n                    }\n\t\t}\n            ],\n            \"properties\" : {\n\t\t\"@message\" : {\n                    \"type\" : \"string\",\n                    \"index\" : \"analyzed\",\n                    \"norms\" : {\n\t\t\t\"enabled\" : false\n                    }\n\t\t},\n\t\t\"@tags\": {\n                    \"type\": \"string\",\n                    \"index\" : \"not_analyzed\",\n                    \"norms\" : {\n\t\t\t\"enabled\" : false\n                    }\n\t\t},\n\t\t\"@timestamp\" : {\n                    \"type\" : \"date\",\n                    \"index\" : \"not_analyzed\"\n\t\t},\n\t\t\"@type\" : {\n                    \"type\" : \"string\",\n                    \"index\" : \"not_analyzed\",\n                    \"norms\" : {\n\t\t\t\"enabled\" : false\n                    }\n\t\t},\n\t\t\"message\" : {\n                    \"type\" : \"string\",\n                    \"index\" : \"analyzed\",\n                    \"norms\" : {\n\t\t\t\"enabled\" : false\n                    }\n\t\t},\n\t\t\"geoip\" : {\n                    \"properties\" : {\n\t\t\t\"location\" : {\n\t\t\t    \"type\" : \"geo_point\"\n\t\t\t}\n\t\t    }\n\t\t}\n            }\n\t}\n    }\n}\n\n" 
